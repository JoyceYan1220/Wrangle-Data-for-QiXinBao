{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from lxml import html\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guarantee(driver,flag,df_flag,infoID):\n",
    "    html=driver.page_source#获取网页的html数据\n",
    "    soup=BeautifulSoup(html,'lxml')#对html进行解析\n",
    "    table_select=soup.find('div',id = infoID)\n",
    "    table = table_select.find('table',class_ = 'table table-bordered')\n",
    "    name=[]\n",
    "    try:\n",
    "        for th in table.find_all('tr')[0].find_all('th'):\n",
    "            name.append(th.get_text())#获取表格的字段名称作为字典的键\n",
    "        #flag = 0 #标记，当爬取字段数据是为0，否则为1\n",
    "        #df_flag = 0 #标记是否创建dataframe\n",
    "        for tr in table.find_all('tr'):\n",
    "        #第一行为表格字段数据，因此跳过第一行\n",
    "            if flag==1:\n",
    "                dic={}\n",
    "                i=0\n",
    "                for td in tr.find_all('td'):\n",
    "                    dic[name[i]]=td.get_text().replace('\\n','').replace('\\r','')\n",
    "                    i+=1\n",
    "                if df_flag == 0:\n",
    "                    df_guarantee = pd.DataFrame.from_dict(dic,orient='index').T\n",
    "                    df_flag = 1\n",
    "                else:\n",
    "                    df_guarantee = df_guarantee.append([dic], ignore_index=True)    \n",
    "            flag=1\n",
    "        df_guarantee = df_guarantee.drop('详情',axis = 1)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    return df_guarantee,flag,df_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guarantee(driver,df_guarantee, flag, df_flag):\n",
    "    #driver.set_page_load_timeout(30)\n",
    "    #time.sleep(3)\n",
    "    #guarantee_page=driver.get('https://www.qixin.com/publicly/5db4a5ed-776b-46a5-a129-648a6f47de34')#使用get方法请求url，因为是模拟浏览器，所以不需要headers信息    \n",
    "    html=driver.page_source#获取网页的html数据\n",
    "    soup=BeautifulSoup(html,'lxml')#对html进行解析\n",
    "    table_select=soup.find('div',id = 'companyEvents')\n",
    "    table = table_select.find('table',class_ = 'table table-bordered')\n",
    "    name=[]\n",
    "    try:\n",
    "        for th in table.find_all('tr')[0].find_all('th'):\n",
    "            name.append(th.get_text())#获取表格的字段名称作为字典的键\n",
    "    except IndexError:\n",
    "        Error = '----------------------------------------------------------------'+'\\n'+\\\n",
    "                '-------------There is No Guarantee Record Here------------------' +'\\n'+\\\n",
    "                '----------------------------------------------------------------'\n",
    "        return Error\n",
    "    else:\n",
    "        #flag = 0 #标记，当爬取字段数据是为0，否则为1\n",
    "        #df_flag = 0 #标记是否创建dataframe\n",
    "        for tr in table.find_all('tr'):\n",
    "        #第一行为表格字段数据，因此跳过第一行\n",
    "            if flag==1:\n",
    "                dic={}\n",
    "                i=0\n",
    "                for td in tr.find_all('td'):\n",
    "                    dic[name[i]]=td.get_text().replace('\\n','').replace('\\r','')\n",
    "                    i+=1\n",
    "                if df_flag == 0:\n",
    "                    df_guarantee = pd.DataFrame.from_dict(dic,orient='index').T\n",
    "                    df_flag = 1\n",
    "                else:\n",
    "                    df_guarantee = df_guarantee.append([dic], ignore_index=True)    \n",
    "            flag=1\n",
    "        df_guarantee = df_guarantee.drop('详情',axis = 1)\n",
    "        return df_guarantee, flag, df_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def page1(driver,infoID):\n",
    "    global df,flag,df_flag\n",
    "    html_source=driver.page_source#获取网页的html数据\n",
    "    tree = html.fromstring(html_source)\n",
    "    \n",
    "    try:\n",
    "        len_page = len(tree.xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[3]/div/nav/ul/li'))\n",
    "        #len_page = len(tree.xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li'))\n",
    "        //*[@id=\"companyEvents\"]/div[3]/div/nav/ul/li[6]/a\n",
    "\n",
    "        if len_page > 0:\n",
    "            time.sleep(2)\n",
    "            i = 2\n",
    "            pre = 0\n",
    "            flag = 0 #标记，当爬取字段数据是为0，否则为1\n",
    "            df_flag = 0 #标记是否创建dataframe\n",
    "            df = []\n",
    "            while i<=len_page-1:\n",
    "                print(i)\n",
    "                print(len_page)\n",
    "                logger.info('start track page')\n",
    "                #b = driver.find_element_by_xpath('//*[@id=\"changeInfo\"]/div[2]/div[2]/nav/ul/li[{}]/a'.format(i))\n",
    "                b = driver.find_element_by_xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[3]/div/nav/ul/li['+str(i)+']/a')\n",
    "                logger.info('track successfully')\n",
    "                cur = b.text \n",
    "                if int(cur) != int(pre) + 1:\n",
    "                    #should_click = driver.find_element_by_xpath('//*[@id=\"changeInfo\"]/div[2]/div[2]/nav/ul/li[5]/a')\n",
    "                    should_click = driver.find_element_by_xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[3]/div/nav/ul/li[5]/a')\n",
    "                    cur = should_click.text\n",
    "                    should_click.click()\n",
    "                    logger.info('click 1 success')\n",
    "                    time.sleep(3)\n",
    "                    change = guarantee(driver,df, flag, df_flag)\n",
    "                    logger.info('getdata success')\n",
    "                    df = change[0]\n",
    "                    flag = change[1]\n",
    "                    df_flag = change[2]\n",
    "                    pre = cur\n",
    "\n",
    "                else:\n",
    "                    driver.execute_script(\"arguments[0].click();\", b)\n",
    "                    logger.info('click 2 success')\n",
    "                    time.sleep(3)\n",
    "                    change = guarantee(driver,df, flag, df_flag)\n",
    "                    df = change[0]\n",
    "                    flag = change[1]\n",
    "                    df_flag = change[2]\n",
    "                    pre = cur\n",
    "                    i += 1\n",
    "                    \n",
    "\n",
    "        else: \n",
    "            change = guarantee(driver,df, flag, df_flag)\n",
    "            df = change[0]\n",
    "            flag = change[1]\n",
    "            df_flag = change[2]\n",
    "    except:\n",
    "        logger.error('cannot retrieve {} page for {}'.format(infoID,num))\n",
    "        return False\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(driver,df, flag, df_flag, infoID):\n",
    "    html=driver.page_source #获取网页的html数据\n",
    "    soup=BeautifulSoup(html,'lxml') #对html进行解析\n",
    "    table_select=soup.find('div',id = infoID)\n",
    "    try:\n",
    "        table = table_select.find('table',class_ = 'table table-bordered margin-t-1x')\n",
    "        logger.info(\"track table success\")\n",
    "        name=[]\n",
    "        for th in table.find_all('tr')[0].find_all('th'):\n",
    "            name.append(th.get_text()) #获取表格的字段名称作为字典的键\n",
    "        logger.info('get key name success')    \n",
    "        \n",
    "        for tr in table.find_all('tr'):\n",
    "            if flag==1:\n",
    "                dic={}\n",
    "                i=0\n",
    "                for td in tr.find_all('td'):\n",
    "                    dic[name[i]]=td.get_text().replace('\\n','')\n",
    "                    i+=1\n",
    "                if df_flag == 0:\n",
    "                    df = pd.DataFrame.from_dict(dic,orient='index').T\n",
    "                    df_flag = 1\n",
    "                else:\n",
    "                    df = df.append([dic], ignore_index=True)\n",
    "            flag=1\n",
    "        logger.info('get value success')\n",
    "        if infoID == 'companyEvents':\n",
    "            df = df.drop('详情',axis = 1)\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        logger.error('cannot retrieve the {} data for {}'.format(infoID,num))\n",
    "        pass\n",
    "    return df,flag,df_flag\n",
    "\n",
    "def page(driver,infoID):\n",
    "    global df,flag,df_flag\n",
    "    html_source=driver.page_source#获取网页的html数据\n",
    "    tree = html.fromstring(html_source)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        len_page = len(tree.xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li'))\n",
    "\n",
    "        if len_page > 0:\n",
    "            time.sleep(2)\n",
    "            i = 2\n",
    "            pre = 0\n",
    "            flag = 0 #标记，当爬取字段数据是为0，否则为1\n",
    "            df_flag = 0 #标记是否创建dataframe\n",
    "            df = []\n",
    "            while i<=len_page-1:\n",
    "                print(i)\n",
    "                print(len_page)\n",
    "                logger.info('start track page')\n",
    "                #b = driver.find_element_by_xpath('//*[@id=\"changeInfo\"]/div[2]/div[2]/nav/ul/li[{}]/a'.format(i))\n",
    "                b = driver.find_element_by_xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li['+str(i)+']/a')\n",
    "                logger.info('track successfully')\n",
    "                cur = b.text \n",
    "                if int(cur) != int(pre) + 1:\n",
    "                    #should_click = driver.find_element_by_xpath('//*[@id=\"changeInfo\"]/div[2]/div[2]/nav/ul/li[5]/a')\n",
    "                    should_click = driver.find_element_by_xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li[5]/a')\n",
    "                    cur = should_click.text\n",
    "                    should_click.click()\n",
    "                    logger.info('click 1 success')\n",
    "                    time.sleep(3)\n",
    "                    change = getData(driver,df, flag, df_flag,infoID)\n",
    "                    logger.info('getdata success')\n",
    "                    df = change[0]\n",
    "                    flag = change[1]\n",
    "                    df_flag = change[2]\n",
    "                    pre = cur\n",
    "\n",
    "                else:\n",
    "                    driver.execute_script(\"arguments[0].click();\", b)\n",
    "                    logger.info('click 2 success')\n",
    "                    time.sleep(3)\n",
    "                    change = getData(driver,df, flag, df_flag,infoID)\n",
    "                    df = change[0]\n",
    "                    flag = change[1]\n",
    "                    df_flag = change[2]\n",
    "                    pre = cur\n",
    "                    i += 1\n",
    "                    \n",
    "\n",
    "        else: \n",
    "            change = getData(driver,df, flag, df_flag, infoID)\n",
    "            df = change[0]\n",
    "            flag = change[1]\n",
    "            df_flag = change[2]\n",
    "    except:\n",
    "        logger.error('cannot retrieve {} page for {}'.format(infoID,num))\n",
    "        return False\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeInfoClean(data,num,name):\n",
    "    data['变更前']=data['变更前'].str.replace('*','')#清除*\n",
    "    data['变更后']=data['变更后'].str.replace('*','')\n",
    "    for ind, row in data.iterrows():   \n",
    "        try:\n",
    "            if row['变更后'].find(\"新增\") != -1:#检查变更后是否有新增标识\n",
    "                continue\n",
    "            elif ((row['变更事项'].find(\"董事\")!= -1) #检查变更事项是否为董事、经理等\n",
    "                or (row['变更事项'].find(\"高管\") != -1)\n",
    "                or (row['变更事项'].find(\"经理\") != -1)\n",
    "                or (row['变更事项'].find(\"法定代表人\") != -1)\n",
    "                or (row['变更事项'].find(\"负责人\") != -1)\n",
    "                or (row['变更事项'].find(\"监事\") != -1)\n",
    "                or (row['变更事项'].find(\"财务负责人\") != -1)) :\n",
    "                continue\n",
    "            elif row['变更后'].find(\"姓名\") != -1: #少数情况检查\n",
    "                continue\n",
    "            else:\n",
    "                data = data.drop(index = ind) #删除其他行\n",
    "        except:\n",
    "            data = data.drop(index = ind) #删除其他行\n",
    "   \n",
    "    data = data.drop('序号',axis=1)#有序号一列可以删去\n",
    "    data['证券代码'] = num\n",
    "    data['证券简称'] = name\n",
    "    order = ['证券代码','证券简称','变更日期','变更事项','变更前','变更后']\n",
    "    data = data[order]\n",
    "    data.to_csv('changeInfo.csv' ,encoding=\"utf_8_sig\", mode='a',index=False, header= None) #输出到CSV,不覆盖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lawSuitsClean(data,num,name):\n",
    "    data.to_csv('lawSuits.csv',encoding=\"utf_8_sig\", mode='a',index=False, header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def companyEvents(data,num,name):\n",
    "    data.to_csv('companyEvents.csv',encoding=\"utf_8_sig\", mode='a',index=False, header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeInfo(driver):\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[2]/a/h2').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test_data = page(driver,infoID)\n",
    "    try:\n",
    "        changeInfoClean(test_data,num,name)\n",
    "    except:\n",
    "        logger.error('clean work failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lawSuits(driver):\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[5]/a/h2').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test_data = page(driver,infoID)\n",
    "    try:\n",
    "        lawSuitsClean(test_data,num,name)\n",
    "    except:\n",
    "        logger.error('clean work failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def companyEvents(driver):\n",
    "    #driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[1]/a/h2').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test_data = page1(driver,infoID)\n",
    "    try:\n",
    "        companyEventsClean(test_data,num,name)\n",
    "    except:\n",
    "        logger.error('clean work failed')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger，if parameter is null return root logger\n",
    "logger = logging.getLogger(\"debugInfo\")\n",
    "logger.setLevel(logging.INFO) \n",
    "\n",
    "# Set up handler\n",
    "fh = logging.FileHandler(\"debug.log\", mode='w', encoding=\"utf-8\")\n",
    "ch = logging.StreamHandler()\n",
    "\n",
    "# Set format for logging output\n",
    "formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(name)s - %(filename)s - %(message)s\",\n",
    "    datefmt='%Y-%m-%d  %H:%M:%S %a')\n",
    "\n",
    "# Set handler\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add handler to logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which table to update? changeInfo, lawSuits, companyEvents\n",
      "companyEvents\n"
     ]
    }
   ],
   "source": [
    "infoID = input(\"Which table to update? changeInfo, lawSuits, companyEvents\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver') \n",
    "driver.get('https://www.qixin.com/search?key=601628&page=1') \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-a5c30ada7c4a>:24: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(search_window[-1])\n",
      "2020-08-24  09:36:33 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - start track page\n",
      "INFO:debugInfo:start track page\n",
      "2020-08-24  09:36:33 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - track successfully\n",
      "INFO:debugInfo:track successfully\n",
      "2020-08-24  09:36:33 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - click 2 success\n",
      "INFO:debugInfo:click 2 success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-24  09:36:36 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - cannot retrieve companyEvents page for 600859\n",
      "ERROR:debugInfo:cannot retrieve companyEvents page for 600859\n",
      "2020-08-24  09:36:36 Mon - debugInfo - <ipython-input-23-bd21f2ac7ce7> - clean work failed\n",
      "ERROR:debugInfo:clean work failed\n",
      "<ipython-input-25-a5c30ada7c4a>:49: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(window[0])\n",
      "2020-08-24  09:36:45 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - cannot retrieve companyEvents page for 600861\n",
      "ERROR:debugInfo:cannot retrieve companyEvents page for 600861\n",
      "2020-08-24  09:36:45 Mon - debugInfo - <ipython-input-23-bd21f2ac7ce7> - clean work failed\n",
      "ERROR:debugInfo:clean work failed\n",
      "2020-08-24  09:36:56 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - start track page\n",
      "INFO:debugInfo:start track page\n",
      "2020-08-24  09:36:56 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - track successfully\n",
      "INFO:debugInfo:track successfully\n",
      "2020-08-24  09:36:56 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - click 2 success\n",
      "INFO:debugInfo:click 2 success\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-24  09:36:59 Mon - debugInfo - <ipython-input-20-8a5be8d18c6f> - cannot retrieve companyEvents page for 600862\n",
      "ERROR:debugInfo:cannot retrieve companyEvents page for 600862\n",
      "2020-08-24  09:36:59 Mon - debugInfo - <ipython-input-23-bd21f2ac7ce7> - clean work failed\n",
      "ERROR:debugInfo:clean work failed\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-a5c30ada7c4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0msearch_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'\\ue007'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'body > div.app-search-enterprise.bg-b6.padding-b-50px > div.container.margin-t-0-6x > div > div.col-md-18 > div.padding-h-1x.border-h-b4.border-t-b4.app-list-items > div.row.bg-white > div:nth-child(1) > div.col-2.clearfix > div.col-2-1 > div.company-title.font-18.font-f1 > a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 搜索公司\n",
    "input_df = pd.read_csv('compy_lst_test.csv', header = 0)\n",
    "ddf = input_df[[\"证券代码\",\"证券简称\"]]\n",
    "for id, row in ddf.iterrows():\n",
    "    num = str(row[0])\n",
    "    name = row[1]\n",
    "    \n",
    "\n",
    "    #num='002348' \n",
    "    search_box = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div[1]/div[3]/span[1]/input[2]')\n",
    "    search_box.send_keys(Keys.CONTROL, 'a')\n",
    "    search_box.send_keys(num)\n",
    "    search_box.send_keys(u'\\ue007') \n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    element = driver.find_element_by_css_selector('body > div.app-search-enterprise.bg-b6.padding-b-50px > div.container.margin-t-0-6x > div > div.col-md-18 > div.padding-h-1x.border-h-b4.border-t-b4.app-list-items > div.row.bg-white > div:nth-child(1) > div.col-2.clearfix > div.col-2-1 > div.company-title.font-18.font-f1 > a')\n",
    "    driver.execute_script(\"arguments[0].click();\", element)                             \n",
    "\n",
    "    ###################爬数据##########################################################\n",
    "\n",
    "    # browser换至当前页面\n",
    "    search_window = driver.window_handles\n",
    "    driver.switch_to_window(search_window[-1])\n",
    "\n",
    "    # 工商变更\n",
    "    try:\n",
    "        driver.find_element_by_xpath('/html/body/div[5]/div[1]/div/div[1]').click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[2]/a/h2').click()\n",
    "    #time.sleep(2)\n",
    "    if infoID == 'changeInfo':\n",
    "        changeInfo(driver)\n",
    "    elif infoID == 'lawSuits':\n",
    "        lawSuits(driver)\n",
    "    elif infoID == 'companyEvents':\n",
    "        companyEvents(driver)\n",
    "    else:\n",
    "        print(\"input error\")\n",
    "    \n",
    "    # 关闭当前页&回到搜索页面\n",
    "    driver.close()\n",
    "    time.sleep(1)\n",
    "    window = driver.window_handles\n",
    "    driver.switch_to_window(window[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-c4d3f5919f9e>:4: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(window[-1])\n"
     ]
    }
   ],
   "source": [
    "# 关闭当前页&回到搜索页面\n",
    "driver.close()\n",
    "window = driver.window_handles\n",
    "driver.switch_to_window(window[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'companyEvents'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-180-e351725e8f9a>:17: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(search_window[-1])\n",
      "2020-08-24  00:07:07 Mon - debugInfo - <ipython-input-177-e1cf1e546ef3> - track table success\n",
      "2020-08-24  00:07:07 Mon - debugInfo - <ipython-input-177-e1cf1e546ef3> - cannot retrieve the companyEvents data for 600859\n",
      "2020-08-24  00:07:07 Mon - debugInfo - <ipython-input-179-899bb5866bd2> - clean work failed\n",
      "<ipython-input-180-e351725e8f9a>:42: DeprecationWarning: use driver.switch_to.window instead\n",
      "  driver.switch_to_window(window[0])\n"
     ]
    }
   ],
   "source": [
    "num='600859' \n",
    "name = 'qwe'\n",
    "search_box = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div[1]/div[3]/span[1]/input[2]')\n",
    "search_box.send_keys(Keys.CONTROL, 'a')\n",
    "search_box.send_keys(num)\n",
    "search_box.send_keys(u'\\ue007') \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "element = driver.find_element_by_css_selector('body > div.app-search-enterprise.bg-b6.padding-b-50px > div.container.margin-t-0-6x > div > div.col-md-18 > div.padding-h-1x.border-h-b4.border-t-b4.app-list-items > div.row.bg-white > div:nth-child(1) > div.col-2.clearfix > div.col-2-1 > div.company-title.font-18.font-f1 > a')\n",
    "driver.execute_script(\"arguments[0].click();\", element)                             \n",
    "\n",
    "###################爬数据##########################################################\n",
    "\n",
    "# browser换至当前页面\n",
    "search_window = driver.window_handles\n",
    "driver.switch_to_window(search_window[-1])\n",
    "\n",
    "# 工商变更\n",
    "try:\n",
    "    driver.find_element_by_xpath('/html/body/div[5]/div[1]/div/div[1]').click()\n",
    "    time.sleep(1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "#driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[2]/a/h2').click()\n",
    "#time.sleep(2)\n",
    "if infoID == 'changeInfo':\n",
    "    changeInfo(driver)\n",
    "elif infoID == 'lawSuits':\n",
    "    lawSuits(driver)\n",
    "elif infoID == 'companyEvents':\n",
    "    companyEvents(driver)\n",
    "else:\n",
    "    print(\"input error\")\n",
    "\n",
    "# 关闭当前页&回到搜索页面\n",
    "driver.close()\n",
    "time.sleep(1)\n",
    "window = driver.window_handles\n",
    "driver.switch_to_window(window[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'changeInfo'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infoID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
