{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from lxml import html\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(driver,df, flag, df_flag, infoID):\n",
    "    html=driver.page_source #获取网页的html数据\n",
    "    soup=BeautifulSoup(html,'lxml') #对html进行解析\n",
    "    table_select=soup.find('div',id = infoID)\n",
    "    try:\n",
    "        table = table_select.find('table',class_ = 'table table-bordered margin-t-1x')\n",
    "        logger.info(\"track table success\")\n",
    "        name=[]\n",
    "        for th in table.find_all('tr')[0].find_all('th'):\n",
    "            name.append(th.get_text()) #获取表格的字段名称作为字典的键\n",
    "        logger.info('get key name success')    \n",
    "        \n",
    "        for tr in table.find_all('tr'):\n",
    "            if flag==1:\n",
    "                dic={}\n",
    "                i=0\n",
    "                for td in tr.find_all('td'):\n",
    "                    dic[name[i]]=td.get_text().replace('\\n','')\n",
    "                    i+=1\n",
    "                if df_flag == 0:\n",
    "                    df = pd.DataFrame.from_dict(dic,orient='index').T\n",
    "                    df_flag = 1\n",
    "                else:\n",
    "                    df = df.append([dic], ignore_index=True)\n",
    "            flag=1\n",
    "        logger.info('get value success')\n",
    "        if infoID == 'companyEvents':\n",
    "            df = df.drop('详情',axis = 1)\n",
    "        else:\n",
    "            pass\n",
    "    except:\n",
    "        logger.error('cannot retrieve the {} data for {}'.format(infoID,num))\n",
    "        pass\n",
    "    return df,flag,df_flag\n",
    "\n",
    "def page(driver,infoID):\n",
    "    global df,flag,df_flag\n",
    "    html_source=driver.page_source#获取网页的html数据\n",
    "    tree = html.fromstring(html_source)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        len_page = len(tree.xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li'))\n",
    "\n",
    "        if len_page > 0:\n",
    "            time.sleep(2)\n",
    "            i = 2\n",
    "            pre = 0\n",
    "            flag = 0 #标记，当爬取字段数据是为0，否则为1\n",
    "            df_flag = 0 #标记是否创建dataframe\n",
    "            df = []\n",
    "            while i<=len_page-1:\n",
    "                print(i)\n",
    "                print(len_page)\n",
    "                logger.info('start track page')\n",
    "                #b = driver.find_element_by_xpath('//*[@id=\"changeInfo\"]/div[2]/div[2]/nav/ul/li[{}]/a'.format(i))\n",
    "                b = driver.find_element_by_xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li['+str(i)+']/a')\n",
    "                logger.info('track successfully')\n",
    "                cur = b.text \n",
    "                if int(cur) != int(pre) + 1:\n",
    "                    #should_click = driver.find_element_by_xpath('//*[@id=\"changeInfo\"]/div[2]/div[2]/nav/ul/li[5]/a')\n",
    "                    should_click = driver.find_element_by_xpath('//*[@id='+'\"'+str(infoID)+'\"'+']/div[2]/div[2]/nav/ul/li[5]/a')\n",
    "                    cur = should_click.text\n",
    "                    should_click.click()\n",
    "                    logger.info('click 1 success')\n",
    "                    time.sleep(3)\n",
    "                    change = getData(driver,df, flag, df_flag,infoID)\n",
    "                    logger.info('getdata success')\n",
    "                    df = change[0]\n",
    "                    flag = change[1]\n",
    "                    df_flag = change[2]\n",
    "                    pre = cur\n",
    "\n",
    "                else:\n",
    "                    driver.execute_script(\"arguments[0].click();\", b)\n",
    "                    logger.info('click 2 success')\n",
    "                    time.sleep(3)\n",
    "                    change = getData(driver,df, flag, df_flag,infoID)\n",
    "                    df = change[0]\n",
    "                    flag = change[1]\n",
    "                    df_flag = change[2]\n",
    "                    pre = cur\n",
    "                    i += 1\n",
    "                    \n",
    "\n",
    "        else: \n",
    "            change = getData(driver,df, flag, df_flag, infoID)\n",
    "            df = change[0]\n",
    "            flag = change[1]\n",
    "            df_flag = change[2]\n",
    "    except:\n",
    "        logger.error('cannot retrieve {} page for {}'.format(infoID,num))\n",
    "        return False\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeInfoClean(data,num,name):\n",
    "    data['变更前']=data['变更前'].str.replace('*','')#清除*\n",
    "    data['变更后']=data['变更后'].str.replace('*','')\n",
    "    for ind, row in data.iterrows():   \n",
    "        try:\n",
    "            if row['变更后'].find(\"新增\") != -1:#检查变更后是否有新增标识\n",
    "                continue\n",
    "            elif ((row['变更事项'].find(\"董事\")!= -1) #检查变更事项是否为董事、经理等\n",
    "                or (row['变更事项'].find(\"高管\") != -1)\n",
    "                or (row['变更事项'].find(\"经理\") != -1)\n",
    "                or (row['变更事项'].find(\"法定代表人\") != -1)\n",
    "                or (row['变更事项'].find(\"负责人\") != -1)\n",
    "                or (row['变更事项'].find(\"监事\") != -1)\n",
    "                or (row['变更事项'].find(\"财务负责人\") != -1)) :\n",
    "                continue\n",
    "            elif row['变更后'].find(\"姓名\") != -1: #少数情况检查\n",
    "                continue\n",
    "            else:\n",
    "                data = data.drop(index = ind) #删除其他行\n",
    "        except:\n",
    "            data = data.drop(index = ind) #删除其他行\n",
    "   \n",
    "    data = data.drop('序号',axis=1)#有序号一列可以删去\n",
    "    data['证券代码'] = num\n",
    "    data['证券简称'] = name\n",
    "    order = ['证券代码','证券简称','变更日期','变更事项','变更前','变更后']\n",
    "    data = data[order]\n",
    "    data.to_csv('changeInfo.csv' ,encoding=\"utf_8_sig\", mode='a',index=False, header= None) #输出到CSV,不覆盖\n",
    "\n",
    "def lawSuitsClean(data,num,name):\n",
    "    data.to_csv('lawSuits.csv',encoding=\"utf_8_sig\", mode='a',index=False, header= None)\n",
    "    \n",
    "def companyEvents(data,num,name):\n",
    "    data.to_csv('companyEvents.csv',encoding=\"utf_8_sig\", mode='a',index=False, header= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeInfo(driver):\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[2]/a/h2').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test_data = page(driver,infoID)\n",
    "    try:\n",
    "        changeInfoClean(test_data,num,name)\n",
    "    except:\n",
    "        logger.error('clean work failed')\n",
    "        \n",
    "def lawSuits(driver):\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[5]/a/h2').click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    test_data = page(driver,infoID)\n",
    "    try:\n",
    "        lawSuitsClean(test_data,num,name)\n",
    "    except:\n",
    "        logger.error('clean work failed')\n",
    "\n",
    "def companyEvents(driver):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logger，if parameter is null return root logger\n",
    "logger = logging.getLogger(\"debugInfo\")\n",
    "logger.setLevel(logging.INFO) \n",
    "\n",
    "# Set up handler\n",
    "fh = logging.FileHandler(\"debug.log\", mode='w', encoding=\"utf-8\")\n",
    "ch = logging.StreamHandler()\n",
    "\n",
    "# Set format for logging output\n",
    "formatter = logging.Formatter(\n",
    "    fmt=\"%(asctime)s - %(name)s - %(filename)s - %(message)s\",\n",
    "    datefmt='%Y-%m-%d  %H:%M:%S %a')\n",
    "\n",
    "# Set handler\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add handler to logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infoID = input(\"Which table to update? changeInfo, lawSuits, companyEvents\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver') \n",
    "driver.get('https://www.qixin.com/search?key=601628&page=1') \n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜索公司\n",
    "input_df = pd.read_csv('compy_lst_test.csv', header = 0)\n",
    "ddf = input_df[[\"证券代码\",\"证券简称\"]]\n",
    "for id, row in ddf.iterrows():\n",
    "    num = str(row[0])\n",
    "    name = row[1]\n",
    "    \n",
    "\n",
    "    #num='002348' \n",
    "    search_box = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div/div[2]/div/div/div/div[1]/div[3]/span[1]/input[2]')\n",
    "    search_box.send_keys(Keys.CONTROL, 'a')\n",
    "    search_box.send_keys(num)\n",
    "    search_box.send_keys(u'\\ue007') \n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    element = driver.find_element_by_css_selector('body > div.app-search-enterprise.bg-b6.padding-b-50px > div.container.margin-t-0-6x > div > div.col-md-18 > div.padding-h-1x.border-h-b4.border-t-b4.app-list-items > div.row.bg-white > div:nth-child(1) > div.col-2.clearfix > div.col-2-1 > div.company-title.font-18.font-f1 > a')\n",
    "    driver.execute_script(\"arguments[0].click();\", element)                             \n",
    "\n",
    "    ###################爬数据##########################################################\n",
    "\n",
    "    # browser换至当前页面\n",
    "    search_window = driver.window_handles\n",
    "    driver.switch_to_window(search_window[-1])\n",
    "\n",
    "    # 工商变更\n",
    "    try:\n",
    "        driver.find_element_by_xpath('/html/body/div[5]/div[1]/div/div[1]').click()\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    #driver.find_element_by_xpath('/html/body/div[2]/div[4]/div/div/div/div/ul/li[2]/a/h2').click()\n",
    "    #time.sleep(2)\n",
    "    if infoID == 'changeInfo':\n",
    "        changeInfo(driver)\n",
    "    elif infoID == 'lawSuits':\n",
    "        lawSuits(driver)\n",
    "    elif infoID == 'companyEvents':\n",
    "        companyEvents(driver)\n",
    "    else:\n",
    "        print(\"input error\")\n",
    "    \n",
    "    # 关闭当前页&回到搜索页面\n",
    "    driver.close()\n",
    "    time.sleep(1)\n",
    "    window = driver.window_handles\n",
    "    driver.switch_to_window(window[0])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
